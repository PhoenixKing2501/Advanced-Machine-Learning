{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Callable, Dict, List, Any\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataframe = pd.read_excel(\"energy+efficiency/ENB2012_data.xlsx\")\n",
    "\n",
    "print(raw_dataframe.head())\n",
    "print('Mean of the raw_dataframe:')\n",
    "print(raw_dataframe.mean())\n",
    "print('Standard deviation of the raw_dataframe:')\n",
    "print(raw_dataframe.std())\n",
    "\n",
    "# Normalizing the data\n",
    "\n",
    "# dataframe = raw_dataframe.copy()\n",
    "dataframe = (raw_dataframe - raw_dataframe.mean()) / (raw_dataframe.max() - raw_dataframe.min())\n",
    "print(dataframe.head())\n",
    "\n",
    "# Shuffle the data\n",
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(dataframe.head())\n",
    "\n",
    "X_train = dataframe.iloc[:, :-2]\n",
    "Y_train = dataframe.iloc[:, -2:]\n",
    "\n",
    "print(X_train.head())\n",
    "print(Y_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataframe['X1'], dataframe['Y1'], 'ro')\n",
    "plt.xlabel('Relative Compactness')\n",
    "plt.ylabel('Heating Load')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(dataframe['X5'], dataframe['Y2'], 'ro')\n",
    "plt.xlabel('Overall Height')\n",
    "plt.ylabel('Cooling Load')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_kernel(\n",
    "    sigma: float,\n",
    "    bandwidth: float,\n",
    "    x: np.ndarray,\n",
    "    y: np.ndarray,\n",
    ") -> float:\n",
    "    \"\"\" Here we define the kernel function. We use the squared exponential kernel. The kernel function is used to calculate the covariance matrix.\n",
    "\n",
    "    Args:\n",
    "        sigma (float) : The standard deviation of the Gaussian distribution.\n",
    "        bandwidth (float) : The bandwidth of the Gaussian distribution.\n",
    "        x (np.ndarray) : The first point at which the kernel function is to be evaluated.\n",
    "        y (np.ndarray) : The second point at which the kernel function is to be evaluated.\n",
    "\n",
    "    Returns:\n",
    "        float: The value of the kernel function at points x and y.\n",
    "    \"\"\"\n",
    "    return np.exp(-1 * np.sum(np.square(x - y)) / (2 * bandwidth ** 2)) * sigma ** 2\n",
    "\n",
    "# END def kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kernel_matrix(\n",
    "    kernel: Callable,\n",
    "    X: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    ") -> np.ndarray:\n",
    "    \"\"\" Here we define the kernel matrix. The kernel matrix is used to calculate the covariance matrix.\n",
    "\n",
    "    Args:\n",
    "        sigma (float) : The standard deviation of the Gaussian distribution.\n",
    "        bandwidth (float) : The bandwidth of the Gaussian distribution.\n",
    "        X (np.ndarray) : The data matrix\n",
    "        Y (np.ndarray) : The data matrix\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The kernel matrix.\n",
    "    \"\"\"\n",
    "\n",
    "    N1 = X.shape[0]\n",
    "    N2 = Y.shape[0]\n",
    "\n",
    "    K = np.zeros((N1, N2))\n",
    "\n",
    "    for i in range(N1):\n",
    "        for j in range(N2):\n",
    "            K[i, j] = kernel(X[i], Y[j])\n",
    "        # END for j\n",
    "    # END for i\n",
    "\n",
    "    return K\n",
    "\n",
    "# END def kernel_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ker_mat = kernel_matrix(lambda x, y: se_kernel(1, 1, x, y), X_train.to_numpy(), X_train.to_numpy())\n",
    "print(ker_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianProcessRegression:\n",
    "    \"\"\" Here we define the GaussianProcessRegression class. \n",
    "        The GaussianProcessRegression class is used to fit the Gaussian Process Regression model \n",
    "                to the data and predict the output for the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernels: List[Callable],\n",
    "    ) -> None:\n",
    "        \"\"\" Here we initialize the GaussianProcessRegression class.\n",
    "\n",
    "        Args:\n",
    "            sigma (float) : The standard deviation of the Gaussian distribution.\n",
    "            bandwidth (float) : The bandwidth of the Gaussian distribution.\n",
    "            X (np.ndarray) : The training data.\n",
    "            Y (np.ndarray) : The output for the training data.\n",
    "        \"\"\"\n",
    "\n",
    "        self.kernels = kernels\n",
    "    # END def __init__\n",
    "\n",
    "    def fit(\n",
    "        self,\n",
    "        X_train: np.ndarray,\n",
    "        Y_train: np.ndarray,\n",
    "    ) -> None:\n",
    "        \"\"\" Here we fit the Gaussian Process Regression model to the data.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray) : The training data.\n",
    "            Y (np.ndarray) : The output for the training data.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.K = [kernel_matrix(k, X_train, X_train) for k in self.kernels]\n",
    "        self.K_inv = [np.linalg.inv(k) for k in self.K]\n",
    "\n",
    "    # END def fit\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        X_test: np.ndarray,\n",
    "    ) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\" Here we predict the output for the test data.\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray) : The test data.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The means of the predicted output for the test data.\n",
    "            np.ndarray: The variance of the predicted output for the test data.\n",
    "        \"\"\"\n",
    "\n",
    "        y_pred_mean = np.zeros((X_test.shape[0],\n",
    "                                Y_train.shape[1]))\n",
    "\n",
    "        y_pred_var = np.zeros((X_test.shape[0],\n",
    "                               Y_train.shape[1]))\n",
    "\n",
    "        for i in range(Y_train.shape[1]):\n",
    "            k_star = kernel_matrix(self.kernels[i], X_test, self.X_train)\n",
    "            y_pred_mean[:, i] = k_star @ self.K_inv[i] @ self.Y_train[:, i]\n",
    "            y_pred_var[:, i] = np.diag(kernel_matrix(self.kernels[i], X_test, X_test) -\n",
    "                                               k_star @ self.K_inv[i] @ k_star.T)\n",
    "\n",
    "        return y_pred_mean, y_pred_var\n",
    "\n",
    "    # END def predict\n",
    "# END class GaussianProcessRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Process Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(\n",
    "    Y_true: np.ndarray,\n",
    "    Y_pred: np.ndarray,\n",
    ") -> float:\n",
    "    \"\"\" Here we calculate the mean squared error.\n",
    "\n",
    "    Args:\n",
    "        Y_true (np.ndarray)\n",
    "        Y_pred (np.ndarray)\n",
    "\n",
    "    Returns:\n",
    "        float: The mean squared error.\n",
    "    \"\"\"\n",
    "    return float(np.mean(np.square(Y_true - Y_pred)))\n",
    "# END def mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test Split (30-70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(X_train)\n",
    "f = 0.3\n",
    "n_train, n_test = N - int(f * N), int(f * N)\n",
    "print(n_train, n_test)\n",
    "\n",
    "X_train, X_test = X_train[:n_train], X_train[n_train:]\n",
    "Y_train, Y_test = Y_train[:n_train], Y_train[n_train:]\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Predictions and Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = [1.5, 1.1]\n",
    "bandwidth = [1, 0.3]\n",
    "\n",
    "kernels = [lambda x, y: se_kernel(s, b, x, y)\n",
    "           for s, b in zip(sigma, bandwidth)]\n",
    "\n",
    "gpr = GaussianProcessRegression(kernels=kernels)\n",
    "gpr.fit(X_train=X_train.to_numpy(),\n",
    "        Y_train=Y_train.to_numpy())\n",
    "\n",
    "Y_pred, var_Y_pred = gpr.predict(X_test=X_test.to_numpy())\n",
    "\n",
    "\n",
    "print(Y_pred.shape, var_Y_pred.shape)\n",
    "\n",
    "print('Mean squared error for Y1:')\n",
    "print(mean_squared_error(Y_test['Y1'].to_numpy(), Y_pred[:, 0]))\n",
    "print('Mean squared error for Y2:')\n",
    "print(mean_squared_error(Y_test['Y2'].to_numpy(), Y_pred[:, 1]))\n",
    "\n",
    "\n",
    "# have grid in the plots\n",
    "plt.plot(Y_test['Y1'].to_numpy(), Y_pred[:, 0], 'ro')\n",
    "line = np.linspace(Y_test['Y1'].min()*1.1, Y_test['Y1'].max()*1.1, 1000)\n",
    "plt.plot(line, line, 'b-')\n",
    "plt.xlabel('Actual Heating Load')\n",
    "plt.ylabel('Predicted Heating Load')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y_pred[:, 0], var_Y_pred[:, 0], 'ro')\n",
    "plt.xlabel('Predicted Heating Load')\n",
    "plt.ylabel('Variance of Predicted Heating Load')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y_test['Y2'].to_numpy(), Y_pred[:, 1], 'ro')\n",
    "line = np.linspace(Y_test['Y2'].min()*1.1, Y_test['Y2'].max()*1.1, 1000)\n",
    "plt.plot(line, line, 'b-')\n",
    "plt.xlabel('Actual Cooling Load')\n",
    "plt.ylabel('Predicted Cooling Load')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y_pred[:, 1], var_Y_pred[:, 1], 'ro')\n",
    "plt.xlabel('Predicted Cooling Load')\n",
    "plt.ylabel('Variance of Predicted Cooling Load')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(\n",
    "    kernels: List[Callable],\n",
    "    X: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    k: int,\n",
    ") -> float:\n",
    "    \"\"\" Here we perform k-fold cross validation.\n",
    "\n",
    "    Args:\n",
    "        sigma (float)\n",
    "        bandwidth (float)\n",
    "        X (np.ndarray) : The training data.\n",
    "        Y (np.ndarray) : The output for the training data.\n",
    "        k (int) : The number of folds.\n",
    "\n",
    "    Returns:\n",
    "        float: The mean squared error.\n",
    "    \"\"\"\n",
    "    N = X.shape[0]\n",
    "    n = N // k\n",
    "    mse = 0\n",
    "    for i in range(k):\n",
    "        X_train = np.concatenate((X[: i * n], X[(i + 1) * n:]))\n",
    "        Y_train = np.concatenate((Y[: i * n], Y[(i + 1) * n:]))\n",
    "        X_test = X[i * n: (i + 1) * n]\n",
    "        Y_test = Y[i * n: (i + 1) * n]\n",
    "        gpr = GaussianProcessRegression(kernels=kernels)\n",
    "        gpr.fit(X_train=X_train, Y_train=Y_train)\n",
    "        Y_pred, _ = gpr.predict(X_test=X_test)\n",
    "        mse += mean_squared_error(Y_test, Y_pred)\n",
    "    # END for\n",
    "    return mse / k\n",
    "# END def cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(\n",
    "    X: np.ndarray,\n",
    "    Y: np.ndarray,\n",
    "    k: int,\n",
    ") -> Tuple[Tuple[float, float], Tuple[float, float]]:\n",
    "    \"\"\" Here we perform grid search to find the best hyperparameters.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray) : The training data.\n",
    "        Y (np.ndarray) : The output for the training data.\n",
    "        k (int) : The number of folds.\n",
    "\n",
    "    Returns:\n",
    "        tuple: The best hyperparameters.\n",
    "    \"\"\"\n",
    "    best_sigma: Tuple[float, float] = (np.nan, np.nan)\n",
    "    best_bandwidth: Tuple[float, float] = (np.nan, np.nan)\n",
    "    best_mse = np.inf\n",
    "\n",
    "    for sigma1 in np.arange(0.1, 2.1, 0.1):\n",
    "        for sigma2 in np.arange(0.1, 2.1, 0.1):\n",
    "            for bandwidth1 in np.arange(0.1, 2.1, 0.1):\n",
    "                for bandwidth2 in np.arange(0.1, 2.1, 0.1):\n",
    "                    kernels = [lambda x, y: se_kernel(sigma1, bandwidth1, x, y),\n",
    "                               lambda x, y: se_kernel(sigma2, bandwidth2, x, y)]\n",
    "                    mse = cross_validation(kernels, X, Y, k)\n",
    "                    \n",
    "                    if mse < best_mse:\n",
    "                        best_mse = mse\n",
    "                        best_sigma = sigma1, sigma2\n",
    "                        best_bandwidth = bandwidth1, bandwidth2\n",
    "                    # END if\n",
    "\n",
    "                # END for\n",
    "            # END for\n",
    "        # END for\n",
    "    # END for\n",
    "\n",
    "    return best_sigma, best_bandwidth\n",
    "\n",
    "# END def grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sigma, best_bandwidth = grid_search(X_train.to_numpy(),\n",
    "                                         Y_train.to_numpy(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_sigma, best_bandwidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = [lambda x, y: se_kernel(s, b, x, y)\n",
    "           for s, b in zip(best_sigma, best_bandwidth)]\n",
    "\n",
    "gpr = GaussianProcessRegression(kernels=kernels)\n",
    "gpr.fit(X_train=X_train.to_numpy(),\n",
    "        Y_train=Y_train.to_numpy())\n",
    "\n",
    "Y_pred, var_Y_pred = gpr.predict(X_test=X_test.to_numpy())\n",
    "\n",
    "\n",
    "print(Y_pred.shape, var_Y_pred.shape)\n",
    "\n",
    "print('Mean squared error for Y1:')\n",
    "print(mean_squared_error(Y_test['Y1'].to_numpy(), Y_pred[:, 0]))\n",
    "print('Mean squared error for Y2:')\n",
    "print(mean_squared_error(Y_test['Y2'].to_numpy(), Y_pred[:, 1]))\n",
    "\n",
    "\n",
    "# have grid in the plots\n",
    "plt.plot(Y_test['Y1'].to_numpy(), Y_pred[:, 0], 'ro')\n",
    "line = np.linspace(Y_test['Y1'].min()*1.1, Y_test['Y1'].max()*1.1, 1000)\n",
    "plt.plot(line, line, 'b-')\n",
    "plt.xlabel('Actual Heating Load')\n",
    "plt.ylabel('Predicted Heating Load')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y_pred[:, 0], var_Y_pred[:, 0], 'ro')\n",
    "plt.xlabel('Predicted Heating Load')\n",
    "plt.ylabel('Variance of Predicted Heating Load')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y_test['Y2'].to_numpy(), Y_pred[:, 1], 'ro')\n",
    "line = np.linspace(Y_test['Y2'].min()*1.1, Y_test['Y2'].max()*1.1, 1000)\n",
    "plt.plot(line, line, 'b-')\n",
    "plt.xlabel('Actual Cooling Load')\n",
    "plt.ylabel('Predicted Cooling Load')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(Y_pred[:, 1], var_Y_pred[:, 1], 'ro')\n",
    "plt.xlabel('Predicted Cooling Load')\n",
    "plt.ylabel('Variance of Predicted Cooling Load')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
